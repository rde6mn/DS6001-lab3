{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 8: Data Management Using `pandas`, Part 1\n",
    "## DS 6001\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0\n",
    "Import the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidetable\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "There are a lot of resources on the internet on the general topic of Python for Data Science, and many of these websites publish lists of the most important Python packages for data science. There are definite disagreements further down on these lists, but the [top](https://www.datacamp.com/blog/top-python-libraries-for-data-science) [spots](https://www.reddit.com/r/Python/comments/uorxt5/does_anyone_use_python_for_a_data_science/) [always](https://www.anaconda.com/topics/best-python-libraries) [include](https://www.geeksforgeeks.org/python-libraries-for-data-science/) numpy and pandas. We've used pandas in every single one of the labs in this course so far, and modules 8 and 9 are entirely about the process of data wrangling and manipulation using pandas.\n",
    "\n",
    "But, there is a package that competes directly with pandas, called [polars](https://pola.rs/). This package has its fans and adherents. But the tenor and tone of the debate over which package to use is more adversarial and heated than I would expect. For many, it is not enough to use polars when it makes sense as part of a larger data science toolkit: polars needs to completely defeat and replace pandas, and send pandas to that great software recycling bin in the sky.\n",
    "\n",
    "As a data professional, you will absolutely be drawn into a conversation at some point that's in reality a small battle in the great pandas vs. polars war. Maybe polars really is the inevitable replacement for pandas, maybe not. But you should know about these options to form a solid opinion so that you can hold your ground in one of these conversations until civility can be reestablished and everyone can just talk about sports or gossip again.\n",
    "\n",
    "### Part a\n",
    "The polars website contains [a page that is directed at pandas users](https://docs.pola.rs/user-guide/migration/pandas/). Please read this page, and find two points made on this page that seem appealing or interesting to you, and describe those points here. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "So, here's the thing. When there's contention between a new and an old way of doing something, the voices on the side of the new way will usually be louder, though not necessarily greater in number. \"This New Way Will Change Everything\" makes a more clickable blog title than \"There's Nothing Wrong With the Way We Do Things Now.\" To see the argument for pandas over polars, look for analyses that aim for an objective comparison. Read this [blog post by Josep Ferrer](https://www.kdnuggets.com/pandas-vs-polars-a-comparative-analysis-of-python-dataframe-libraries), or find a different post or analysis that defends pandas, and in a one or two of your own sentences, describe the best argument for pandas. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Do a search on a social media platform of your choice, and find an instance of somebody commenting on the polars vs. pandas debate. Copy and paste some text from this post that your find compelling or interesting, along with the link. Also, do you agree with this opinion, or not, and why? [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "As someone who either currently, or who will soon be a data professional, you will be a member of a community of similar professionals. We learn a great deal from our peers in these kinds of communities of practice. Have a conversation with someone who is a data professional, whether that is someone you work with, or someone you know, or someone that someone you know knows, and ask them about their thoughts on polars vs pandas. What are their thoughts on this? [4 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e\n",
    "Based on your reading and thoughts from parts (a) through (d), do you think you will try to learn how to use polars, or will you stick with pandas, or try using both? (No wrong answers, just curious about where you land on this.)\n",
    "\n",
    "By the way: We are going to continue to use pandas in this course, but if you would like to train on polars, one good option is [this course](https://app.datacamp.com/learn/courses/introduction-to-polars) on Datacamp. You should have free access to Datacamp from UVA, but if not, please let me know so we can get you access. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Please use pandas, not polars, for this problem.\n",
    "\n",
    "For this problem, you will be working with the [2017 Workplace Health in America survey](https://www.cdc.gov/workplace-health-promotion/php/data/index.html) which was conducted by the Centers for Disease Control and Prevention. According to the survey's [guidance document](https://www.cdc.gov/workplace-health-promotion/media/pdfs/2024/06/2017-WHA-Guidance-Document-for-Use-of-Public-Data-files-508.pdf):\n",
    "\n",
    "> The Workplace Health in America (WHA) Survey gathered information from a cross-sectional, nationally representative sample of US worksites. The sample was drawn from the Dun & Bradstreet (D&B) database of all private and public employers in the United States with at least 10 employees. Like previous national surveys, the worksite served as the sampling unit rather than the companies or firms to which the worksites belonged. Worksites were selected using a stratified simple random sample (SRS) design, where the primary strata were ten multi-state regions defined by the Centers for Disease Control and Prevention (CDC), plus an additional stratum containing all hospital worksites. \n",
    "\n",
    "The data contain over 300 features that report the industry and type of company where the respondents are employed, what kind of health insurance and other health programs are offered, and other characteristics of the workplaces including whether employees are allowed to work from home and the gender and age makeup of the workforce. The data are full of interesting information, but in order to make use of the data a great deal of data manipulation is required first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "The raw data are stored in an ASCII file on the 2017 Workplace Health in America survey [homepage](https://www.cdc.gov/workplacehealthpromotion/survey/data.html). Load the raw data directly into Python without downloading the data onto your harddrive. Then use the `.info(verbose=True)` method on the dataframe to show summary information about the data. Based on what you see (it's NOT necessary to usE any other code) answer the following questions:\n",
    "\n",
    "* How many rows?\n",
    "* How many columns?\n",
    "* How many columns have a float data type (numeric with decimals) and how many have an object data type (text or strings)?\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b \n",
    "Create a new variable in Python's memory to store a working version of the data. In the working version, delete all of the columns except for the following:\n",
    "\n",
    "* `Industry`: 7 Industry Categories with NAICS codes\n",
    "\n",
    "* `Size`: 8 Employee Size Categories\n",
    "\n",
    "* `OC3` Is your organization for profit, non-profit, government?\n",
    "\n",
    "* `HI1` In general, do you offer full, partial or no payment of premiums for personal health insurance for full-time employees?\n",
    "\n",
    "* `HI2` Over the past 12 months, were full-time employees asked to pay a larger proportion, smaller proportion or the same proportion of personal health insurance premiums?\n",
    "\n",
    "* `HI3`: Does your organization offer personal health insurance for your part-time employees?\n",
    "\n",
    "* `CP1`: Are there health education programs, which focus on skill development and lifestyle behavior change along with information dissemination and awareness building?\n",
    "\n",
    "* `WL6`: Allow employees to work from home?\n",
    "\n",
    "* Every column that begins `WD`, expressing the percentage of employees that have certain characteristics at the firm\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Column names like 'OC3' and 'CP1' do not convey the meaning or intuition of a feature, so let's choose better names. The [codebook](https://www.cdc.gov/workplace-health-promotion/media/pdfs/2024/06/2017-WHA-Datafile-Codebook-508.pdf) for the WHA data contain short descriptions of the meaning of each of the columns in the data. Use these descriptions to decide on better and more intuitive names for the columns in the working version of the data, and rename the columns accordingly. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "Throughout the data, numeric values are used to represent categories. For example, for the feature that asks whether a workplace allows employees to work from home, 1 means yes and 2 means no. But it is more intuitive, less error prone, and easier for data visualization and other analyses if we replace these numbers with text labels that tell us explicitly what the categories represent. The following questions ask you to replace numeric values with text labels for these categorical features.\n",
    "\n",
    "#### Step i\n",
    "The industry column is currently coded numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry\n",
       "5.0    551\n",
       "1.0    525\n",
       "3.0    433\n",
       "4.0    429\n",
       "7.0    338\n",
       "2.0    311\n",
       "6.0    255\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whpps['Industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the codebook, these values represent:\n",
    "\n",
    "* 1 = Industry Category 1: NAICS Sectors: 11, 21, 22, 23, 31-33\n",
    "* 2 = Industry Category 2: NAICS Sectors: 42, 44-45, 48-49\n",
    "* 3 = Industry Category 3: NAICS Sectors: 71, 72, 81\n",
    "* 4 = Industry Category 4: NAICS Sectors: 51, 52, 53, 54, 55, 56\n",
    "* 5 = Industry Category 5: NAICS Sectors: 61, 62 (excluding hospital worksites)\n",
    "* 6 = Industry Category 6: NAICS Sectors: 92\n",
    "* 7 = Industry Category 7: Hospital worksites (NAICS6 = 622110, 622210, 622310)\n",
    "\n",
    "NAICS stands for North American Industry Classification System. According to their [website](https://www.naics.com/), their industry coding system\n",
    "\n",
    "> is a standardized system used to classify businesses based on their primary activities. This NAICS Code classification helps in the collection, analysis, and publication of statistical data related to the U.S. economy. Accurate NAICS Information is crucial for businesses because they affect eligibility for government contracts, loans, and tax benefits, and they facilitate better communication with government agencies.\n",
    "\n",
    "Use the [dictionary of NAICS industrial codes](https://www.naics.com/search-naics-codes-by-industry/) to lookup the NAICS codes that each category of the Industry feature represents, then place descriptive labels on the categories of the industry column in the working data. This is a bit of a pain because you need to find a succinct but descriptive way to label each category. For example, Industry=1 represents Agriculture, Forestry, Fishing and Hunting (NAICS code 11), Mining (NAICS code 21), Utilities (NAICS code 22), Construction (NAICS code 23), and Manufacturing (NAICS code 31-33). You can use the label 'Agriculture, Construction, Manufacturing' if you want, or something else. Do your best.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step ii\n",
    "Using the codebook, recode the \"size\" feature to have three categories: \"Small\" for workplaces with fewer than 100 employees, \"Medium\" for workplaces with at least 100 but fewer than 500 employees, and \"Large\" for companies with at least 500 employees. [Note: Python dataframes have an attribute `.size` that reports the space the dataframe takes up in memory. Don't confuse this attribute with the column named \"Size\" in the raw data.] [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step iii\n",
    "Use the codebook to write accurate and descriptive labels for each category for each categorical column in the working data. Then apply all of these labels to the data at once. Code \"Legitimate Skip\", \"Don't know\", \"Refused\", and \"Blank\" as `np.nan` missing values. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step iv\n",
    "The features that measure the percent of the workforce with a particular characteristic use the codes 997, 998, and 999 to represent \"Don't know\", \"Refusal\", and \"Blank/Invalid\" respectively. If we don't change these, all numeric results that use these features will be wrong. Replace these values with missing values for all of the percentage features at the same time. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e\n",
    "As you proceed through a data wrangling process, viewing the data at each step is important to determine whether your code has worked correctly and to see the next problems that need to be solved. Sorting the data is one of the most important and useful ways to look at different parts of the data that are not displayed by default within the `.head()` of a dataframe.\n",
    "\n",
    "Sort the working data by industry in ascending alphabetical order. Within industry categories, sort the rows by size in ascending alphabetical order. Within groups with the same industry and size, sort by percent of the workforce that is under 30 in descending numeric order. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part f\n",
    "Sometimes important features have missing values for one reason or another, and depending on our purposes, we may not be able to use rows with these missing values. In those situations, it is often easier to delete the rows with missing values.\n",
    "\n",
    "There is one row in the working data that has a missing value for industry. Delete this row.  [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part g\n",
    "Sometimes we need to take a continuous-valued feature and turn it into a categorical one for some analysis.\n",
    "\n",
    "Create a new feature named `gender_balance` that has three categories: \"Mostly men\" for workplaces with between 0% and 35% female employees, \"Balanced\" for workplaces with more than 35% and at most 65% female employees, and \"Mostly women\" for workplaces with more than 65% female employees. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part h\n",
    "Currently all of the categorical features in the data are stored as \"object\" data types, which is the same data type as strings. But there are additional methods and display properties that are available if we instead convert these features to a \"category\" data type.\n",
    "\n",
    "Change the data type of all categorical features in the working data from \"object\" to \"category\". [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "Just like SQL is a mechanism for deriving answers from the information stored within a database, pandas can be a tool for getting answers to questions using a dataframe.\n",
    "\n",
    "The following questions ask you to perform some simple analyses using data wrangling alone.\n",
    "\n",
    "### Part a\n",
    "I am looking for a job with a small workplace that lets me work from home, but I am worried about whether the job will provide me with health insurance.\n",
    "\n",
    "Filter the data to only those rows that represent small workplaces that allow employees to work from home. Then report how many of these workplaces offer full insurance, partial insurance, and no insurance. Report the percent, cumulative count, and cumulative percent in addition to the counts. \n",
    "\n",
    "This is much easier if you use the `sidetable` package. Any answer that does not use `sidetable` will receive no credit.\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Anything that can be done in SQL can be done with `pandas`. The next several questions ask you to write `pandas` code to match a given SQL query. \n",
    "\n",
    "But first, to check that the SQL query and `pandas` code yield the same result, create a new database using the `sqlite3` package and input the cleaned WHA data as a table in this database. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Some hospital workplaces lowered their insurance premiums. I want to know whether these hospitals were large, medium, or small employers, for profit or non-profit, whether they offer full or partial insurance, and whether they have part-time employees. Using SQL, I can get an answer to these questions with this query:\n",
    "```\n",
    "SELECT size, \n",
    "    type, \n",
    "    premiums AS insurance, \n",
    "    parttime\n",
    "FROM whpps\n",
    "WHERE industry = 'Hospitals' \n",
    "    AND premium_change='Smaller'\n",
    "```\n",
    "Write pandas code that replicates the results of this SQL query. Your feature names might be different from the ones listed in the query, depending on the column names you chose earlier. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "Are there differences across industry in the percent of the workforce that are women, under 30, or over 60?\n",
    "\n",
    "Using SQL, I can get an answer to these questions with this query:\n",
    "```\n",
    "SELECT industry, \n",
    "    AVG(percent_female) AS percent_female, \n",
    "    AVG(percent_under30) AS percent_under30,\n",
    "    AVG(percent_over60) AS percent_over60\n",
    "FROM whpps\n",
    "GROUP BY industry\n",
    "ORDER BY percent_female DESC\n",
    "```\n",
    "Write pandas code that replicates the results of this SQL query. Your feature names might be different from the ones listed in the query, depending on the column names you chose earlier. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e\n",
    "Are there differences in whether full, partial, or no health insurance is provided to employees based on whether the workplace is mostly men, mostly women, or is gender balanced?\n",
    "\n",
    "Using SQL, I can get an answer to this question with this query:\n",
    "```\n",
    "SELECT gender_balance, \n",
    "    premiums, \n",
    "    COUNT(*)\n",
    "FROM whpps\n",
    "GROUP BY gender_balance, premiums\n",
    "HAVING gender_balance is NOT NULL \n",
    "    AND premiums is NOT NULL\n",
    "```\n",
    "Write pandas code that replicates the results of this SQL query. Your feature names might be different from the ones listed in the query, depending on the column names you chose earlier. \n",
    "\n",
    "Note: the rows of your pandas output will be sorted in a different order than the rows of the SQL query. That happens due to the default sorting order (SQL sorts alphabetically, pandas sorts according to the order supplied in the `pd.cut()` method you used earlier.) It's a pain to get the sorting to match, so don't! Also, don't worry if the columns have different names. Just confirm the same data is contained in each result. [8 points]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001summer2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
